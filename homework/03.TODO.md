# Домашнее задание №3
03.08-08.08
## Содержание
1. [ Задание ](#task)
    - [ Checklist ](#checklist)
2. [ Настройка асинхронной(async) репликации ](#async_replication)
    - [ Запуск трех независимых узлов MySQL ](#launch_databases)
    - [ Конфигурирование master-а ](#master_config)
    - [ Конфигурирование первого slave-а ](#first_slave_config)
    - [ Конфигурирование второго slave-а ](#second_slave_config)
3. [ Применение миграций ](#migration)
4. [ Нагрузочное тестирование на чтение ](#read_stress_testing)
    - [ Подготовка ](#read_stress_testing_preparation)
    - [ Выполнение ](#read_stress_testing_implementation)
    - [ Результаты ](#read_results_stress_testing_implementation)
5. [ Подключение row based binary logging format ](#enable_row_based)
6. [ Подключение GTID ](#gtid)
7. [ Настроить полусинхронную репликацию ](#semi_sync_replica)
8. [ Нагрузочное тестирование на запись ](#write_stress_testing)
    - [ Подготовка ](#write_stress_testing_preparation)
    - [ Выполнение ](#write_stress_testing_implementation)
    - [ Результаты ](#write_results_stress_testing_implementation)
9. [ Назначение нового master-узла ](#master_promoting)

<a name="task"></a>
## Задание
Полусинхронная репликация

Цель:
-   В результате выполнения ДЗ вы настроите полусинхронную репликацию, протестируете ее влияние на производительность системы и убедитесь, что теперь вы не теряете транзакции в случае аварии.

В данном задании тренируются навыки:
-   обеспечение отказоустойчивости проекта;
-   администрирование MySQL;
-   настройка репликации;
-   проведение нагрузочных тестов.

Cдача результата ДЗ в виде исходного кода на github и отчета в текстовом виде.

Требования:
-   В отчете корректно описано, как настроена репликация.
-   2 запроса переведено на чтение со слейва.
-   Нагрузочное тестирование показало, что нагрузка перешла на слейв.
-   В отчете описано как включить row-based репликацию и GTID.
-   Проведен эксперимент по потере и непотере транзакций при аварийной остановке master.

<a name="checklist"></a>
## Checklist
1. Провести нагрузочный тест master.
    - Замерить нагрузку master-узла MySQL (CPU, la, disc usage, memory usage).
2. Настроить асинхронную репликацию (+ 2 slave).
3. Выбрать 2 самых частых и тяжелых по логике работы сайта запроса и перенести их на чтение со slave.
4. Провести нагрузочный тест после перевода нагрузки на чтение со slave.
    - Замерить нагрузку master-узла MySQL (CPU, la, disc usage, memory usage).
5. Включить row-based репликацию.
6. Включить GTID.
6. Настроить полусинхронную репликацию.
7. Создать нагрузку на запись, при этом: 
    - считать сколько мы успешно сделали записей;
    - до завершения нагрузки, убить MySQL на master-узле.
8. Назначить один из существующих slave -> master.
    - Переключаем на него второй слейв
9. Проверить, есть ли потери транзакции.

<a name="async_replication"></a>
## Настройка асинхронной(async) репликации

<a name="launch_databases"></a>
### Запуск трех независимых узлов MySQL
Для того, чтобы запустить в docker-ах три instance-а MySQL баз данных(которые в дальнейшем станут двумя slave-ами и 
одним master-ом), необходимо выполнить:
```shell script
docker-compose -f 03.docker-compose.yml up -d sn_mysql_node1 sn_mysql_node2 sn_mysql_node3
```

<a name="master_config"></a>
### Конфигурирование master-а
Заходим в master-container:
```shell script
docker exec -it sn_mysql_node1 bash
```

Создаем папку mysql в директории */var/log/* папку mysql и даем права доступа к ней пользователю *mysql*:
```shell script
mkdir /var/log/mysql && chown mysql:mysql /var/log/mysql
```

Устанавливаем текстовый редактор для конфигурирования, по умолчанию редактор не идет в комплектации container-а:
```shell script
apt-get -y update && apt-get -y install vim
```

Открываем конфигурацию, которая располагается по пути **/etc/mysql/conf.d/mysql.cnf**, c помощью **vi**:
```shell script
vi /etc/mysql/conf.d/mysql.cnf
```

Дописываем в секцию **[mysqld]** следующие строки:
```textmate
[mysqld]
bind-address = sn_mysql_node1
server-id = 1
default_authentication_plugin=mysql_native_password
log-bin = /var/log/mysql/mysql-bin.log
tmpdir = /tmp
binlog_format = STATEMENT
max_binlog_size = 500M
sync_binlog = 1
slow_query_log
``` 

Выходим из контейнера и рестартуем его:
```shell script
docker restart sn_mysql_node1
```

Заходим опять в контейнер
```shell script
docker exec -it sn_mysql_node1 bash
```

Переходим в оболочку mysql и вводим *password* пароль:
```shell script
mysql -u root -p
```

Создаем пользователя для репликации:
```mysql based
create user 'replica'@'%' IDENTIFIED BY 'Repl1c@P@$$';
```

Наделяем созданного пользователя полномочиями:
```mysql based
GRANT REPLICATION SLAVE ON *.* TO 'replica'@'%';
```

Вызываем команду *show master* для того, чтобы определить **MASTER_LOG_FILE** и **MASTER_LOG_POS**, которые понадобятся
нам в дальнейшем для настройки slave-ов:
```mysql based
show master status;
+------------------+----------+--------------+------------------+-------------------+
| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
+------------------+----------+--------------+------------------+-------------------+
| mysql-bin.000001 |      665 |              |                  |                   |
+------------------+----------+--------------+------------------+-------------------+
```

<a name="first_slave_config"></a>
### Конфигурирование первого slave-а
Заходим в первый slave-container:
```shell script
docker exec -it sn_mysql_node2 bash
```

Создаем папку mysql в директории */var/log/* папку mysql и даем права доступа к ней пользователю *mysql*:
```shell script
mkdir /var/log/mysql && chown mysql:mysql /var/log/mysql
```

Устанавливаем текстовый редактор для конфигурирования, по умолчанию редактор не идет в комплектации container-а:
```shell script
apt-get -y update && apt-get -y install vim
```
Открываем конфигурацию, которая располагается по пути **/etc/mysql/conf.d/mysql.cnf**, c помощью **vi**:
```shell script
vi /etc/mysql/conf.d/mysql.cnf
```
Дописываем в секцию **[mysqld]** следующие строки:
```textmate
[mysqld]
bind-address = sn_mysql_node2
server-id = 2
default_authentication_plugin=mysql_native_password
log_bin = /var/log/mysql/mysql-bin.log
tmpdir = /tmp
binlog_format = STATEMENT
max_binlog_size = 500M
sync_binlog = 1
slow_query_log   = 1
``` 
Выходим из контейнера и рестартуем его:
```shell script
docker restart sn_mysql_node2
```

Заходим опять в контейнер
```shell script
docker exec -it sn_mysql_node2 bash
```

Переходим в оболочку mysql и вводим *password* пароль:
```shell script
mysql -u root -p
```

Вносим информацию о master-е:
```mysql based
CHANGE MASTER TO
    MASTER_HOST='sn_mysql_node1',
    MASTER_USER='replica',
    MASTER_PASSWORD='Repl1c@P@$$',
    MASTER_LOG_FILE='mysql-bin.000001',
    MASTER_LOG_POS=665;
```

Запускаем slave:
```mysql based
start slave;
```

Выводим сводную информацию о состоянии slave-а:
```mysql based
show slave status\G
*************************** 1. row ***************************
               Slave_IO_State: Waiting for master to send event
                  Master_Host: sn_mysql_node1
                  Master_User: replica
                  Master_Port: 3306
                Connect_Retry: 60
              Master_Log_File: mysql-bin.000001
          Read_Master_Log_Pos: 665
               Relay_Log_File: 2cc3d71a57d9-relay-bin.000002
                Relay_Log_Pos: 324
        Relay_Master_Log_File: mysql-bin.000001
             Slave_IO_Running: Yes
            Slave_SQL_Running: Yes
...
```
<a name="second_slave_config"></a>
### Конфигурирование второго slave-а
Заходим во второй slave-container:
```shell script
docker exec -it sn_mysql_node3 bash
```

Создаем папку mysql в директории */var/log/* папку mysql и даем права доступа к ней пользователю *mysql*:
```shell script
mkdir /var/log/mysql && chown mysql:mysql /var/log/mysql
```

Устанавливаем текстовый редактор для конфигурирования, по умолчанию редактор не идет в комплектации container-а:
```shell script
apt-get -y update && apt-get -y install vim
```

Открываем конфигурацию, которая располагается по пути **/etc/mysql/conf.d/mysql.cnf**, c помощью **vi**:
```shell script
vi /etc/mysql/conf.d/mysql.cnf
```

Дописываем в секцию **[mysqld]** следующие строки:
```textmate
[mysqld]
bind-address = sn_mysql_node3
server-id = 3
default_authentication_plugin=mysql_native_password
log_bin = /var/log/mysql/mysql-bin.log
tmpdir = /tmp
binlog_format = STATEMENT
max_binlog_size = 500M
sync_binlog = 1
slow_query_log   = 1
``` 

Выходим из контейнера и рестартуем его:
```shell script
docker restart sn_mysql_node3
```

Заходим опять в контейнер
```shell script
docker exec -it sn_mysql_node3 bash
```

Переходим в оболочку mysql и вводим *password* пароль:
```shell script
mysql -u root -p
```

Вносим информацию о master-е:
```mysql based
CHANGE MASTER TO
    MASTER_HOST='sn_mysql_node1',
    MASTER_USER='replica',
    MASTER_PASSWORD='Repl1c@P@$$',
    MASTER_LOG_FILE='mysql-bin.000001',
    MASTER_LOG_POS=665;
```
Запускаем slave:
```mysql based
start slave;
```

Выводим сводную информацию о состоянии slave-а:
```mysql based
show slave status\G
*************************** 1. row ***************************
               Slave_IO_State: Waiting for master to send event
                  Master_Host: sn_mysql_node1
                  Master_User: replica
                  Master_Port: 3306
                Connect_Retry: 60
              Master_Log_File: mysql-bin.000001
          Read_Master_Log_Pos: 665
               Relay_Log_File: 2a7d4f1b68e0-relay-bin.000002
                Relay_Log_Pos: 324
        Relay_Master_Log_File: mysql-bin.000001
             Slave_IO_Running: Yes
            Slave_SQL_Running: Yes
...
```

<a name="migration"></a>
## Применение миграций

Заполним базу данными с прошлого задания (из бэкапа)

```shell script
cat sntest_bkp.sql | docker exec -i sn_mysql_node1 /usr/bin/mysql -u root --password=secretpass sntest
```

Теперь перейдем в контейнеры slave-ов и проверим, что в базе данных *sntest* появились таблицы и данные.
Ниже представлен пример для первого slave-а.
```shell script
docker exec -it sn_mysql_node2 bash
mysql -u root -p
```
```mysql based
mysql> use sntest;
mysql> show tables;
+------------------+
| Tables_in_sntest |
+------------------+
| d_interests      |
| friends          |
| interests        |
| posts            |
| users            |
+------------------+
mysql> select count(*) from users;
+----------+
| count(*) |
+----------+
|  1041178 |
+----------+
```

<a name="read_stress_testing"></a>
## Нагрузочное тестирование на чтение
Необходимо с помощью утилиты [wrk](https://github.com/wg/wrk) реализовать нагрузочный тест, который бы состоял из двух
тяжелых запросов на чтение с сайта.

Под это требования отлично подойдет поиск анкет пользователей, имя и фамилия которых начинаются на заданную подстроку 
(предыдущее домашнее задание). В качестве подстроки выберем те строки, при мощи которых Backend вернет наибольшее
количество анкет. В моем случае, это name=*k* second_name=*r* 47096 записей, и name=*n* second_name=*l* 150460 записей.

<a name="read_stress_testing_preparation"></a>
### Подготовка

Запускаем backend c подключенной мастер-нодой:
```shell script
go run cmd/main.go
```

<a name="read_stress_testing_implementation"></a>
### Выполнение
Запускаем нагрузочные тесты из двух разных терминалов:
```shell script
wrk http://127.0.0.1/search/user -s 03.search_1.lua --latency -t 10 -c 100 -d 60s
```
```shell script
wrk http://127.0.0.1/search/user -s 03.search_2.lua --latency -t 10 -c 100 -d 60s
```

Замеряем нагрузку на master-node:
```shell script
docker stats sn_mysql_node1 > 03.master_dump_before.txt
```
Ждем окончания нагрузочного теста, который идет 60s и так же жмем Ctrl + C.

Перезапускаем backend, но уже на slave-node, который только лишь на чтение (меняем в конфиге порт на 3307)):
```shell script
go run cmd/main.go
```

Запускаем нагрузочные тесты из двух разных терминалов:
```shell script
wrk http://127.0.0.1/search/user -s 03.search_1.lua --latency -t 10 -c 100 -d 60s
```
```shell script
wrk http://127.0.0.1/search/user -s 03.search_2.lua --latency -t 10 -c 100 -d 60s
```

Замеряем нагрузку на master-node:
```shell script
docker stats sn_mysql_node1 > 03.master_dump_after.txt
```
Ждем окончания нагрузочного теста, который идет 60s и так же жмем Ctrl + C.

<a name="read_results_stress_testing_implementation"></a>
### Результаты
Детально с результатами метрик на master-узле до и после перевода нагрузки на slave-узел можно ознакомиться 
[тут](03.master_dump_before.txt) и
[тут](03.master_dump_after.txt).
Из результатов видно, что при переводе нагрузки с master на slave нагрузка:
- CPU упала c ***~110%*** на ***~1%***;
- RAM не изменилась с ***~5.33%*** на ***~5.33%***;
- NET I/O возросла с ***~9.54MB / 479MB*** на ***~9.77MB / 484MB***;
- BLOCK I/O не изменилась с ***~0B / 0B*** на ***~0B / 0B***;

Потребление CPU существенно снизилось исходя из того, что вычисления теперь легли на плечи slave-узла. Однако 
потребление памяти master-узлом практически не изменилось в связи с тем, что данные, которые мы записывали на 
master-узел никуда не делись и просто-напросто "закешировались".

<a name="enable_row_based"></a>
## Подключение row based binary logging format
Для того, чтобы понять, какой именно сейчас у нас стоит тип для binary logging format-a, необходимо зайти в каждый из
docker-контейнеров, перейти в оболочку mysql и выполнить:
```mysql based
show variables like 'binlog_format';
```

Во всех трех docker-container-ах должны увидеть следующее:<br />
```
+---------------+-----------+
| Variable_name | Value     |
+---------------+-----------+
| binlog_format | STATEMENT |
+---------------+-----------+
```

Для того, чтобы поменять STATEMENT binary logging format на ROW, необходимо: 
- перейти в каждый из docker container-ов MySQL;
```shell script
docker exec -it sn_mysql_node1 bash
docker exec -it sn_mysql_node2 bash
docker exec -it sn_mysql_node3 bash
```

- открыть конфигурацию, располагающуюся по пути: **/etc/mysql/conf.d/mysql.cnf**;
- изменить строку **binlog_format = STATEMENT** на **binlog_format = ROW**;
- перезапустить каждый из контейнеров:
```shell script
docker restart sn_mysql_node1 sn_mysql_node2 sn_mysql_node3
```
При успешном конфигурировании во всех трех docker-container-ах должны увидеть следующее:
```mysql based
docker exec -it sn_mysql_node1 mysql -u root -p
show variables like 'binlog_format';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| binlog_format | ROW   |
+---------------+-------+
```

<a name="gtid"></a>
## Подключение GTID
Для того, чтобы понять, включен ли у нас режим GTID, необходимо зайти в каждый из docker-контейнеров, перейти в 
оболочку mysql и выполнить:
```mysql based
show variables like 'gtid_mode';
```
Во всех трех docker-container-ах должны увидеть следующее:<br />
```
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| gtid_mode     | OFF   |
+---------------+-------+
```

Для того, чтобы поменять GTID mode с OFF на ON, необходимо: 
- перейти в каждый из docker container-ов MySQL;
```shell script
docker exec -it sn_mysql_node1 bash
docker exec -it sn_mysql_node2 bash
docker exec -it sn_mysql_node3 bash
```
- открыть конфигурацию, располагающуюся по пути: **/etc/mysql/conf.d/mysql.cnf**;
- вконец добавить строки 
```text
[mysqld]
gtid_mode = on
enforce_gtid_consistency = true
```
- перезапустить каждый из контейнеров:
```shell script
docker restart sn_mysql_node1
docker restart sn_mysql_node2
docker restart sn_mysql_node3
```

При успешном конфигурировании во всех трех docker-container-ах должны увидеть следующее:
```mysql based
show variables like 'gtid_mode';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| gtid_mode     | ON    |
+---------------+-------+
```

Переходим на каждый из slave-ов, далее в оболочку MySQL и выполняем следующее:
```mysql based
STOP SLAVE;
CHANGE MASTER TO MASTER_AUTO_POSITION = 1;
START SLAVE;
```

<a name="semi_sync_replica"></a>
## Настроить полусинхронную репликацию
Переходим на master, затем в mysql оболочку и применяем команду:
```mysql based
INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so';
```

Так же переходим на каждую slave реплику и применяем команду:
```mysql based
INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';
```

Если все прошло успешно, то на master при введении команды:
```mysql based
SELECT
    PLUGIN_NAME, PLUGIN_STATUS
FROM
    INFORMATION_SCHEMA.PLUGINS
WHERE
    PLUGIN_NAME LIKE '%semi%';
```

Должны увидеть следующее:
```
+----------------------+---------------+
| PLUGIN_NAME          | PLUGIN_STATUS |
+----------------------+---------------+
| rpl_semi_sync_master | ACTIVE        |
+----------------------+---------------+
```

А на slave узлах при введении той же команды должны увидеть:
```
+---------------------+---------------+
| PLUGIN_NAME         | PLUGIN_STATUS |
+---------------------+---------------+
| rpl_semi_sync_slave | ACTIVE        |
+---------------------+---------------+
```

Так же необходимо в конфигурации master узла(располагающуюся по пути: **/etc/mysql/conf.d/mysql.cnf**) задать параметры 
**включения режима репликации** и **время ожидания ответа в мс**
```shell script
[mysqld]
rpl_semi_sync_master_enabled=1
rpl_semi_sync_master_timeout=1000 # 1 second
```

А так же на slave-ах:
```shell script
[mysqld]
rpl_semi_sync_slave_enabled=1
```

И перезапускаем docker container-ы:
```shell script
docker restart sn_mysql_node1
docker restart sn_mysql_node2
docker restart sn_mysql_node3
```

Проверяем, что конфигурация принялась успешно.
На master-е в оболочке MySQL выполняем команду:
```mysql based
show variables like 'rpl_semi_sync_master_enabled';
show variables like 'rpl_semi_sync_master_timeout';
```
Если все ок, то вывод будет таким:<br/>
```
+------------------------------+-------+
| Variable_name                | Value |
+------------------------------+-------+
| rpl_semi_sync_master_enabled | ON    |
+------------------------------+-------+
+------------------------------+-------+
| Variable_name                | Value |
+------------------------------+-------+
| rpl_semi_sync_master_timeout | 1000  |
+------------------------------+-------+
```


На slave-ах в оболочке MySQL выполняем команду:
```mysql based
show variables like 'rpl_semi_sync_slave_enabled';
```
Если все ок, то вывод будет таким:
```
+-----------------------------+-------+
| Variable_name               | Value |
+-----------------------------+-------+
| rpl_semi_sync_slave_enabled | ON    |
+-----------------------------+-------+
```

## !! остановился здесь

<a name="write_stress_testing"></a>
## Нагрузочное тестирование на запись
<a name="write_stress_testing_implementation"></a>
### Выполнение
Для осуществления нагрузки на запись, воспользуемся готовым герератором учеток. (Количество зададим 1000.)
Запускаем app.
```shell script
go run .\cmd\main.go
```
Запускаем генератор.
```shell script
go run .\cmd\usergen\main.go
```

Ждем пару секунд и убиваем master-узел командой:
```shell script
docker rm -f sn_mysql_node1
```

Заканчиваем операцию записи и смотрим, сколько удалось сделать записей в БД:
До нагрузки
```shell script
1041178
```

После нагрузки, на node2
```shell script
1041627
```

После нагрузки, на node3
```shell script
1041627
```

Получилось **449** новых записей. На каждом из slave-ах получаем одно и то же число.

При этом смотрим, сколько транзакций удалось получить и сколько применить на каждом из slave-узле. На каждом slave-е 
выполняем команду:
```mysql based
show slave status\G
```

и смотрим на переменные, такие как:
```shell script
Retrieved_Gtid_Set: 5e5e8621-034b-11ec-817e-0242ac120002:1-886
Executed_Gtid_Set: 5e5e8621-034b-11ec-817e-0242ac120002:1-886
```

Так же можем явно запросить, например, переменную **gtid_executed**:
```mysql based
show variables like 'gtid_executed';
```
и получим следующее:
```
+---------------+--------------------------------------------+
| Variable_name | Value                                      |
+---------------+--------------------------------------------+
| gtid_executed | 5e5e8621-034b-11ec-817e-0242ac120002:1-886 |
+---------------+--------------------------------------------+
```

Переходим в каждый из slave-узлов и удостоверяемся в отсутствии подключения к master-узлу:
```shell script
show slave status\G
```
Должны на каждом из slave-узле увидеть следующую ошибку:
```
Last_IO_Error: error reconnecting to master 'replica@sn_mysql_node1:3306' - retry-time: 60 retries: 7 message: Unknown MySQL server host 'sn_mysql_node1' (11)
```

<a name="write-results-stress-testing-implementation"></a>
### Результаты
В результате выполнения квази-нагрузочного(т.к. все таки было прерывание) тестирования на запись в master-узел было 
обнаружено следующее:
- успешно записанных записей в master, число которых мы залогировали, оказалось 449;
- связь с master-узлом на обоих slave-ах потеряна;
- на стороне обоих slave-узлах величины переменных *Retrieved_Gtid_Set* и *Executed_Gtid_Set* равны значению
5e5e8621-034b-11ec-817e-0242ac120002:1-886 соответственно;
- количество записей на обоих slave-узлах ровно 449.

Если подвести итог, то при включении GTID все транзакции, которые были успешно выполнены, как на стороне master, так и 
всех его slave-узлах, были залогированы на стороне клиентского приложения. Ни одна из транзакций на стороне slave-узла потеряна не была.

<a name="master_promoting"></a>
## Назначение нового master-узла
Переходим на тот slave-узел, которых хотим назначить master-ом, например, sn_mysql_node2:
```shell script
docker exec -it sn_mysql_node2 bash
mysql -u root -p
```

Останавливаем режим SLAVE:
```mysql based
stop slave;
```

Создаем пользователя для репликации:
```mysql based
create user 'replica'@'%' IDENTIFIED BY 'Repl1c@P@$$';
```

Наделяем созданного пользователя полномочиями:
```mysql based
GRANT REPLICATION SLAVE ON *.* TO 'replica'@'%';
```

Перенастраиваем master на себя:
```mysql based
reset master;
```

Выходим из docker container-а и заходим в контейнер sn_mysql_node3, в оболочку mysql:
```mysql based
stop slave;
CHANGE MASTER TO MASTER_HOST='sn_mysql_node2';
start slave;
```

Проверяем, что на slave-узле, все работает и ему удалось подсоединиться к новому master-у:
```mysql based
show slave status\G
```

Если все настроили корректно, должны увидеть следующее:<br/>
```
Slave_IO_Running: Yes
Slave_SQL_Running: Yes
```
